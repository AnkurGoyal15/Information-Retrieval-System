{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quora Question Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this task, for a given user query I had to find which is the most similar question from the given set of questions. A system is to be designed which will be able to give top-3 question suggestions for the given query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><a href=\"http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv\">DataSet Link</a></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pipeline.png\" alt=\"Italian Trulli\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started by importing the necessary libraries. `re` was used for preprocessing the text of the data, removing unwanted characters or noise from the data. `Pandas` is used for reading the data in a row and column format binding it in a dataframe. `Matplotlib` was used for plotting the statistics of the data. To visualise the plots within jupyter notebook `%matplotlib inline` was added. `Pickle` was used to save the modified dataframes, vocabulary and embeddings of the data, so that it can be later reused by just loading the specific pickle file. `BeautifulSoup` was imported for removing any kind of *HTML* tags present in the data. `Numpy` was imported to handle multi-dimensional arrays and since the input, output, predictions from the model were an array, numpy was quite useful. Then, I imported `NLTK` a natural language processing toolkit to remove stopwords from the data like *if, or, him* etc. which does not give any important information. `Gensim` library was imported to load Google's `Word2Vec` which converted each of the word in to a 300 dimensional vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: I did not use stemming, since stemming usually takes each word to its root and sometimes that root word is not there in the pre-trained word2vec models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below libraries were imported as and when they were required I collated them to one cell. There are many other libraries that were used which I have not put in this cell and you will find them in later sections as the implementation proceeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /users/aditya.sharma/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np                                                                \n",
    "import nltk                                      \n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords                                \n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv\"\n",
    "original_data=pd.read_csv(url,error_bad_lines=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output first few rows of the data to see how it looks like. As per my observation, we need three columns for this task namely *question1*, *question2* and *is_duplicate*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there are any `null` values in the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data.isnull().values.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the three null values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = original_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404287, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I will need the `original_data` later on, I copy it into a new variable called `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = original_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for data imbalancing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id              149263\n",
      "qid1            149263\n",
      "qid2            149263\n",
      "question1       149263\n",
      "question2       149263\n",
      "is_duplicate    149263\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (data[data.is_duplicate == 1].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per my observation this dataset doesn't have data imbalancing issue, since both the classes have if not equal but fair amount of records in each class. The class label `0` has around 250K records whereas class label `1` has around 150K records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.gca()\n",
    "data['is_duplicate'].hist(ax=ax)\n",
    "plt.xlabel('is_duplicate',fontsize=20)\n",
    "plt.ylabel('questions',fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.title('Labels vs. Questions Plot',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the stopwords that are there in the `nltk` library which will be removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'she', 'when', 'has', 'once', \"couldn't\", 'my', \"doesn't\", 'as', 'can', 'hers', 'own', 'that', 'shouldn', 'not', 'shan', \"you'll\", 'are', 'doing', 'ours', 'under', \"haven't\", 'hasn', \"hasn't\", 'who', 'they', 'weren', 'he', 'll', 'them', 'how', 'am', 'didn', 'or', \"mustn't\", 'him', 'itself', 'now', \"it's\", \"mightn't\", 'a', 'until', 'up', 'myself', 'aren', 'we', 'into', 'below', 'been', 'should', 'during', \"wouldn't\", \"weren't\", 'there', 'mustn', 'of', 'with', 'himself', 'off', 'any', 'against', 'further', 'herself', 'where', \"you're\", 'these', 'such', 'what', 'ma', 'the', \"you've\", 'than', 'to', 'again', \"aren't\", 'being', 'but', 've', 'only', 'which', 'while', \"won't\", 'ain', 'their', \"shouldn't\", 'those', 'you', 'won', 'theirs', \"shan't\", 'out', 're', 'through', 't', \"wasn't\", 'this', 'was', 'in', 'if', 'it', 'at', 'other', 'about', 'd', \"she's\", 'needn', 'why', 'over', 'more', 'don', 'm', 'o', 'mightn', 'so', 'down', 'haven', 'whom', 'too', 'then', 'i', 'just', 'ourselves', 'were', \"that'll\", 'very', 'will', 'y', 'our', 'her', 'here', 'having', 'and', 'yourselves', 'doesn', 'its', 'each', 'do', 's', 'had', 'few', 'wouldn', 'for', \"should've\", 'by', 'is', \"don't\", 'an', 'your', 'because', 'yourself', 'have', 'yours', 'before', 'from', 'same', 'nor', 'between', 'does', 'above', \"hadn't\", \"needn't\", 'all', 'no', \"didn't\", 'on', 'couldn', 'hadn', \"isn't\", 'after', 'both', 'did', 'most', 'me', 'wasn', 'his', 'be', 'isn', \"you'd\", 'some', 'themselves'}\n"
     ]
    }
   ],
   "source": [
    "stop = set(stopwords.words('english')) \n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I defined `sentence_to_wordlist` which takes each sentence from one of the two columns `question1` and `question2`. On each sentence it applies beautifulsoup for removing html tags if any. Then on that string I applied `regular expression` for some text preprocessing like include upper and lower case alphabets, 0-9 numbers, correct short forms and so on.\n",
    "Then applied `.lower()` to bring everything to lowercase to maintain regularity in every word and `.split()` method to convert the sentence into list of words. Finally, on these list of words I iterated one by one to check if that word is not a `stopword` if not then it is returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_wordlist(sentence):\n",
    "    \n",
    "    \n",
    "    sentence = BeautifulSoup(sentence)  \n",
    "    sentence = sentence.get_text()\n",
    "\n",
    "    sentence = re.sub(r\"[^A-Za-z%@#$&*]\", \" \", sentence)\n",
    "    sentence = re.sub(r\"what's\", \"what is \", sentence)\n",
    "    sentence = re.sub(r\"\\'s\", \" \", sentence)\n",
    "    sentence = re.sub(r\"\\'ve\", \" have \", sentence)\n",
    "    sentence = re.sub(r\"can't\", \"cannot \", sentence)\n",
    "    sentence = re.sub(r\"n't\", \" not \", sentence)\n",
    "    sentence = re.sub(r\"i'm\", \"i am \", sentence)\n",
    "    sentence = re.sub(r\"\\'re\", \" are \", sentence)\n",
    "    sentence = re.sub(r\"\\'d\", \" would \", sentence)\n",
    "    sentence = re.sub(r\"\\'ll\", \" will \", sentence)\n",
    "    sentence = re.sub(r\",\", \" \", sentence)\n",
    "    sentence = re.sub(r\"\\.\", \" \", sentence)\n",
    "    sentence = re.sub(r\"\\/\", \" \", sentence)\n",
    "    sentence = re.sub(r\"\\^\", \" ^ \", sentence)\n",
    "    sentence = re.sub(r\"\\+\", \" + \", sentence)\n",
    "    sentence = re.sub(r\"\\=\", \" = \", sentence)\n",
    "    sentence = re.sub(r\"'\", \" \", sentence)\n",
    "    sentence = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", sentence)\n",
    "    sentence = re.sub(r\":\", \" : \", sentence)\n",
    "    sentence = re.sub(r\" e g \", \" eg \", sentence)\n",
    "    sentence = re.sub(r\" b g \", \" bg \", sentence)\n",
    "    sentence = re.sub(r\" u s \", \" american \", sentence)\n",
    "    sentence = re.sub(r\"\\0s\", \"0\", sentence)\n",
    "    sentence = re.sub(r\"e - mail\", \"email\", sentence)\n",
    "    sentence = re.sub(r\"j k\", \"jk\", sentence)\n",
    "    sentence = re.sub(r\"\\s{2,}\", \" \", sentence)\n",
    "    \n",
    "    sentence = sentence.lower().split()\n",
    "\n",
    "\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    sentence = [w for w in sentence if not w in stops]\n",
    "\n",
    "    return(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I defined the two columns on which I applied the preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['question1', 'question2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I iterated over each row by using dataframes function called `iterrows()` which iterates over each record or row of the dataframe. For each row I iterated over the two columns namely `question1`, `question2` and then for each record I called the `sentence_to_wordlist()` function passing in the row and one of the two columns. Using pandas `at()` function I updated for each row both columns `question1` and `question2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/aditya.sharma/super-resolution-master_new/SR_new/lib/python3.5/site-packages/bs4/__init__.py:273: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    }
   ],
   "source": [
    "for indices, record in data.iterrows():\n",
    "        # Iterate through the text of both questions of the row\n",
    "        for column in columns:\n",
    "            data.at[indices, column] =  sentence_to_wordlist(record[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I print the first few rows of the modified dataframe and we can see that both the `question1` and `question2` columns have been converted into list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[step, step, guide, invest, share, market, india]</td>\n",
       "      <td>[step, step, guide, invest, share, market]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[story, kohinoor, koh, noor, diamond]</td>\n",
       "      <td>[would, happen, indian, government, stole, koh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>[increase, speed, internet, connection, using,...</td>\n",
       "      <td>[internet, speed, increased, hacking, dns]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>[mentally, lonely, solve]</td>\n",
       "      <td>[find, remainder, math, 23, 24, math, divided,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>[one, dissolve, water, quikly, sugar, salt, me...</td>\n",
       "      <td>[fish, would, survive, salt, water]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  [step, step, guide, invest, share, market, india]   \n",
       "1   1     3     4              [story, kohinoor, koh, noor, diamond]   \n",
       "2   2     5     6  [increase, speed, internet, connection, using,...   \n",
       "3   3     7     8                          [mentally, lonely, solve]   \n",
       "4   4     9    10  [one, dissolve, water, quikly, sugar, salt, me...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0         [step, step, guide, invest, share, market]             0  \n",
       "1  [would, happen, indian, government, stole, koh...             0  \n",
       "2         [internet, speed, increased, hacking, dns]             0  \n",
       "3  [find, remainder, math, 23, 24, math, divided,...             0  \n",
       "4                [fish, would, survive, salt, water]             0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I save the `preprocessed_data` as pickle file so that I can just load it and reuse it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Saving the dataframe as a pickle file acquires less space on the disk as well as keeps the format intact when reloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_preprocessed.pickle', 'wb') as sub_data:\n",
    "    pickle.dump(data, sub_data, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_preprocessed.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After I preprocessed the sentences into list of words, next I assigned each unique word in the whole corpuse a number, so that I could pass this as an input to the model and also create a word2vec representation of these vocabularies (numbers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For doing this, I initialised a dictionary of variable `vocabulary()` which stored each word as a key and a number as a value respectively. Another variable called `inverse_vocabulary()` which is a list that holds the value or number for each unique word. It was initialised which an `<unk>` token since we want to zero pad the words with a number zero I did not want to assign any word a number 0. Hence, initialised with a `<unk>` token which holds the value zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to above, I again iterate over the dataframe using `iterrows()` function, for each question in a row I iterate over all the words one by one. First I check whether the word is already in the dictionary `vocabulary()` if the word is not there then a value based on the length of the `inverse_vocabulary` is assigned to that new word (key), the inverse_vocabulary is updated with the new value along with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To update the dataframe `data` with numbers, I have a list named `sentence_to_numbers` which will append a value (number) for each word. Then using `at()` function the dataframe for each question of the particular row was updated with the list of word indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = dict()\n",
    "inverse_vocabulary = ['<unk>']  \n",
    "\n",
    "for indices, record in data.iterrows():\n",
    "         for column in columns:\n",
    "\n",
    "            sentence_to_numbers = []  \n",
    "            for word in record[column]:\n",
    "\n",
    "               \n",
    "                if word not in vocabulary:\n",
    "                    vocabulary[word] = len(inverse_vocabulary)\n",
    "                    sentence_to_numbers.append(len(inverse_vocabulary))\n",
    "                    inverse_vocabulary.append(word)\n",
    "                else:\n",
    "                    sentence_to_numbers.append(vocabulary[word])\n",
    "\n",
    "            data.at[indices, column] =  sentence_to_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will save the `data_to_number` representation in a pickle file, so that I can reuse it and save time for later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_number_representation.pickle', 'wb') as sub_data:\n",
    "    pickle.dump(data, sub_data, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will load it as `modified_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_number_representation.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 2, 3, 4, 5, 6]</td>\n",
       "      <td>[1, 1, 2, 3, 4, 5]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[7, 8, 9, 10, 11]</td>\n",
       "      <td>[12, 13, 14, 15, 16, 8, 9, 10, 11, 17]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>[18, 19, 20, 21, 22, 23]</td>\n",
       "      <td>[20, 19, 24, 25, 26]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>[27, 28, 29]</td>\n",
       "      <td>[30, 31, 32, 33, 34, 32, 35, 34, 33]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>[36, 37, 38, 39, 40, 41, 42, 43, 44, 45]</td>\n",
       "      <td>[46, 12, 47, 41, 38]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                 question1  \\\n",
       "0   0     1     2                     [1, 1, 2, 3, 4, 5, 6]   \n",
       "1   1     3     4                         [7, 8, 9, 10, 11]   \n",
       "2   2     5     6                  [18, 19, 20, 21, 22, 23]   \n",
       "3   3     7     8                              [27, 28, 29]   \n",
       "4   4     9    10  [36, 37, 38, 39, 40, 41, 42, 43, 44, 45]   \n",
       "\n",
       "                                question2  is_duplicate  \n",
       "0                      [1, 1, 2, 3, 4, 5]             0  \n",
       "1  [12, 13, 14, 15, 16, 8, 9, 10, 11, 17]             0  \n",
       "2                    [20, 19, 24, 25, 26]             0  \n",
       "3    [30, 31, 32, 33, 34, 32, 35, 34, 33]             0  \n",
       "4                    [46, 12, 47, 41, 38]             0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also saved the `vocabulary` and `inverse_vocabulary` variable in a pickle file, since we would need them while creating the embedding matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocabulary.pickle', 'wb') as vocab:\n",
    "    pickle.dump(vocabulary, vocab, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('inverse_vocab.pickle', 'wb') as inverse_vocab:\n",
    "    pickle.dump(inverse_vocabulary, inverse_vocab, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocabulary.pickle', 'rb') as handle:\n",
    "    vocabulary = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I created the embedding matrix for my vocabulary. For which I used `gensim` library and google's pre-trained word2vec model. Google's pre-trained word2vec model gives a 300 dimensional vector for each word which will be fed to the `Embedding layer` of my model. Since, I will pad my sentences with a zero, I initialise the embedding matrix's zeroth element as zero. The size of the embedding matrix will be `(Size of Vocabulary + 1 (for zero) X 300 (embedding dim))`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I iterated over vocabulary and for each word corresponding to its index I store the 300 dimensional vector in the `embeddings` numpy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the word is not there in the Google's pretrained model then that word will be randomly initialised, since the `embeddings` array is initialised randomly beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin',binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "embeddings = 1 * np.random.randn(len(vocabulary) + 1, embedding_dim)  # Initialising the embedding matrix randomly\n",
    "embeddings[0] = 0  \n",
    "# Build the embedding matrix\n",
    "for word, index in vocabulary.items():\n",
    "    if word in word2vec.vocab:\n",
    "        embeddings[index] = word2vec.word_vec(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85159, 300)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape #since there are 85158 words in the dataset and 0 is <unk> token which will be a zero padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I stored the embedding matrix as a pickle file too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embeddings.pickle', 'wb') as embed:\n",
    "    pickle.dump(embeddings, embed, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I imported all the Model related libraries that I used for splitting the data, padding the sentences to equal length, keras conv, merge, dropout, maxpooling etc. layers and the Model (Funtional API)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, Flatten, Conv1D, MaxPooling1D, Embedding, Merge, Dropout, GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare my data for feeding it into the model, I will first split the data into training and validation data. Validation data will help me to tune my hyperparameters, change the architecture, optimizer. It will also tell me whether my Model is `overfitting` on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this I define a new dataframe `new_data` which has only two columns namely `question1` and `question2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['is_duplicate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the input to my model will be a fixed size input it is important to keep all the sentences/sequences of same length. For that, I pad all the sentences with zeros based on the length of the sentence that has the maximum words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = max(new_data.question1.map(lambda x: len(x)).max(),new_data.question2.map(lambda x: len(x)).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I take `random_state=13` which will divide the training and validation data in the same fashion no matter how many times I run it. If I change the `random_state` the manner in which data is divided will also change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, Y_train, Y_validation = train_test_split(new_data,labels,random_state=13, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, my network will have two inputs, the data was divided as `question1` and `question2` in a dictionary fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = {'question1': X_train.question1, 'question2': X_train.question2}\n",
    "val = {'question1': X_validation.question1, 'question2': X_validation.question2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, using `itertools()` function on both training and validation data, I padded each sentence with zeros to make each sequence of same size i.e. `103`. By default, Keras will pad zeros in a `pre-order` i.e. before the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dataset, side in itertools.product([train, val], ['question1', 'question2']):\n",
    "    dataset[side] = pad_sequences(dataset[side], maxlen=max_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I printed the shape of training and validation data for both `question1` and `question2` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((323429, 103), (323429, 103))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['question1'].shape,train['question2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80858, 103), (80858, 103))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val['question1'].shape,val['question2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"siamese.png\" alt=\"Italian Trulli\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use a `Siamese` based architecture. Since the data is distributed in such a fashion wherein there are two questions and we have to find similarity between them, so using siamese is good way to go about this problem statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I import few more modules like `LSTM`, `BatchNormalization` etc. for various experiments that I did. I also imported `earlystopping`, `modelcheckpoint` and `reducelronplateau` which will stop the model if the `validation_loss` will stop decreasing after a certain point, saving best weights in the complete training again based on `validation_loss` and finally decay the `learning_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, LSTM, Lambda,Dropout,merge,Lambda,Reshape\n",
    "from keras.layers import BatchNormalization, Bidirectional, GlobalMaxPool1D\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers\n",
    "import numpy.random as rng\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras import models\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used batch_size of 64, number of training epochs were 25 and weights were initialised using Xavier uniform initialisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 \n",
    "n_epoch = 15\n",
    "W_init = keras.initializers.glorot_uniform(seed=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried many architectures out of which I finalised the below architecture. I achieved `~81%` accuracy on the validation data and on training data I achieved `~100%` accuracy. The model definitely overfits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I use Keras Functional API, I defined three functions namely `embedding()`, `middle()` and `predict()`. The embedding function took embedding matrix as an input and was Trainable as True when the network was getting trained. The embedding output is feeded into the middle function module as input on which the maxpooling, lstm and dense layers are applied. The dense layer outputs a 128 feature maps which are then passed to the predict function which computes an L1 distance on these feature maps and then using a Dense layer with one neuron outputs a prediction of 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/aditya.sharma/super-resolution-master_new/SR_new/lib/python3.5/site-packages/ipykernel_launcher.py:61: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_5 (InputLayer)             (None, 103)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_6 (InputLayer)             (None, 103)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)          (None, 103, 300)      25547700    input_5[0][0]                    \n",
      "                                                                   input_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)   (None, 11, 300)       0           embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)   (None, 11, 300)       0           embedding_3[1][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                    (None, 200)           400800      max_pooling1d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                    (None, 200)           400800      max_pooling1d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 128)           25728       lstm_4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 128)           25728       lstm_5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                  (None, 128)           0           dense_4[0][0]                    \n",
      "                                                                   dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 1)             129         merge_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 26,400,885\n",
      "Trainable params: 26,400,885\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 323429 samples, validate on 80858 samples\n",
      "Epoch 1/15\n",
      "323429/323429 [==============================] - 199s - loss: 0.4820 - acc: 0.7644 - val_loss: 0.4428 - val_acc: 0.7887\n",
      "Epoch 2/15\n",
      "323429/323429 [==============================] - 199s - loss: 0.3664 - acc: 0.8333 - val_loss: 0.4352 - val_acc: 0.8020\n",
      "Epoch 3/15\n",
      "323429/323429 [==============================] - 199s - loss: 0.2748 - acc: 0.8805 - val_loss: 0.4456 - val_acc: 0.8083\n",
      "Epoch 4/15\n",
      "323429/323429 [==============================] - 198s - loss: 0.1987 - acc: 0.9172 - val_loss: 0.4871 - val_acc: 0.8081\n",
      "Epoch 5/15\n",
      "323429/323429 [==============================] - 198s - loss: 0.1433 - acc: 0.9421 - val_loss: 0.5768 - val_acc: 0.8004\n",
      "Epoch 6/15\n",
      "323429/323429 [==============================] - 198s - loss: 0.1062 - acc: 0.9579 - val_loss: 0.6742 - val_acc: 0.8023\n",
      "Epoch 7/15\n",
      "323429/323429 [==============================] - 198s - loss: 0.0837 - acc: 0.9672 - val_loss: 0.7558 - val_acc: 0.7988\n",
      "Epoch 8/15\n",
      "323429/323429 [==============================] - 198s - loss: 0.0682 - acc: 0.9737 - val_loss: 0.8367 - val_acc: 0.7968\n",
      "Epoch 9/15\n",
      "323429/323429 [==============================] - 198s - loss: 0.0570 - acc: 0.9785 - val_loss: 0.8474 - val_acc: 0.7906\n",
      "Epoch 10/15\n",
      "323392/323429 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9813\n",
      "Epoch 00009: reducing learning rate to 0.00010000000474974513.\n",
      "323429/323429 [==============================] - 198s - loss: 0.0495 - acc: 0.9813 - val_loss: 0.8731 - val_acc: 0.8026\n",
      "Epoch 11/15\n",
      "323429/323429 [==============================] - 198s - loss: 0.0255 - acc: 0.9907 - val_loss: 1.0015 - val_acc: 0.7984\n",
      "Epoch 12/15\n",
      "323429/323429 [==============================] - 198s - loss: 0.0178 - acc: 0.9934 - val_loss: 1.0751 - val_acc: 0.8001\n",
      "Epoch 13/15\n",
      "323429/323429 [==============================] - 198s - loss: 0.0147 - acc: 0.9943 - val_loss: 1.1448 - val_acc: 0.7970\n",
      "Epoch 14/15\n",
      "323429/323429 [==============================] - 198s - loss: 0.0130 - acc: 0.9946 - val_loss: 1.1901 - val_acc: 0.7981\n",
      "Epoch 15/15\n",
      "323429/323429 [==============================] - 198s - loss: 0.0119 - acc: 0.9950 - val_loss: 1.2397 - val_acc: 0.7955\n"
     ]
    }
   ],
   "source": [
    "question1_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "question2_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "\n",
    "\n",
    "def embedding():\n",
    "    \n",
    "    embedding_layer = Embedding(len(embeddings), 300, weights=[embeddings], input_length=max_seq_length, trainable=False)\n",
    "    encoded_question1 = embedding_layer(question1_input)\n",
    "    encoded_question2 = embedding_layer(question2_input)\n",
    "    return encoded_question1,encoded_question2\n",
    "\n",
    "def middle(q): \n",
    "    x = MaxPooling1D(10,padding='same')(q)\n",
    "    x = LSTM(200, return_sequences=False,kernel_initializer=W_init)(x)\n",
    "    x = Dense(128, activation=\"relu\",kernel_initializer=W_init)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def predict(encoded_q1,encoded_q2):\n",
    "# Calculates the distance\n",
    "    \n",
    "    L1_distance = lambda x: K.abs(x[0]-x[1])\n",
    "    both = merge([encoded_q1,encoded_q2], mode = L1_distance, output_shape=lambda x: x[0])\n",
    "    prediction = Dense(1,activation='sigmoid',kernel_initializer=W_init)(both)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "\n",
    "encoded_question1,encoded_question2 = embedding()\n",
    "encoded_q1 = middle(encoded_question1)\n",
    "encoded_q2 = middle(encoded_question2)\n",
    "prediction = predict(encoded_q1,encoded_q2)\n",
    "    \n",
    "quora = Model([question1_input, question2_input], [prediction])\n",
    "\n",
    "optimizer = Adam(lr=0.001,decay=0.0)\n",
    "\n",
    "quora.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "quora.summary()\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=20, verbose=0,mode='auto')\n",
    "ckpt = ModelCheckpoint(filepath='quora_lstm_max10.h5', save_best_only=True,monitor='val_acc', mode='auto')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=7, verbose=1, epsilon=1e-4,mode='auto')\n",
    "\n",
    "quora_trained = quora.fit([train['question1'], train['question2']], Y_train, batch_size=batch_size, epochs=n_epoch,\n",
    "                            callbacks=[earlyStopping, ckpt, reduce_lr_loss],\n",
    "                            validation_data=([val['question1'], val['question2']], Y_validation))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breaking the network to extract output of 128 feature maps from the middle( ) function by creating a new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I load the model again which has both weights and model, then just save the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/aditya.sharma/super-resolution-master_new/SR_new/lib/python3.5/site-packages/keras/engine/topology.py:1231: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n"
     ]
    }
   ],
   "source": [
    "quora = models.load_model('quora_lstm_max10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora.save_weights('quora_lstm_max10_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I created a new model which takes two inputs and outputs two outputs, for each of the two questions it will output a feature map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora1 = Model([question1_input, question1_input], [encoded_q1,encoded_q2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I saved the combined model & weights and just weights file for this new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora1.save('quora_lstm_max10_dense.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora1.save_weights('quora_lstm_max10_dense_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training data predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prediction = quora1.predict([train['question1'],train['question2']]) #training predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prediction = np.array(train_prediction) #converting the list of predictions into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 323429, 128)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the predictions as a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_predictions.npy',train_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the output of `train_prediction` returns two predictions for `question1` and `question2`. I now reshape it to a one output which will have a shape `(2 X 323429,128)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = np.reshape(train_prediction,(-1,128)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(646858, 128)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation data predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_prediction = quora1.predict([val['question1'],val['question2']]) #valid predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_prediction = np.array(val_prediction) #converting the list of predictions into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 80858, 128)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('val_predictions.npy',val_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = np.reshape(val_prediction,(-1,128)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161716, 128)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I use the `original_data` that I had defined in the starting and will append the `question2` with `question1` to make it one single column of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, Y_train, Y_validation = train_test_split(original_data,original_data.is_duplicate, random_state=13,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = X_train.question1.append(X_train.question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns = ['questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(646858, 1)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = X_validation.question1.append(X_validation.question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = val_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = val_data.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.columns = ['questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161716, 1)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** I use 400K questions against which a query question will be compared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I divide the `train_pred` into two 400k and after 400K take 2K predictions as a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred = train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(646858, 128)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_pred = val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161716, 128)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_questions = val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161716, 1)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_questions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_questions = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(646858, 1)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_questions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brute-Force Method for Finding the Top-3 Closest from the Training data for a given Input Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_array = np.zeros((100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def comparison(query):\n",
    "    arr = []\n",
    "    for i in range(data_pred.shape[0]):\n",
    "            predict = np.linalg.norm(query - data_pred[i])\n",
    "            arr.append(predict)\n",
    "    hp = np.array(heapq.nsmallest(3, range(len(arr)), arr.__getitem__))\n",
    "    return hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I took only 100 query questions since this method takes 313 seconds to output top-3 suggestions for each input query time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313.1226750000005\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.clock()\n",
    "for i in range(100):\n",
    "    main_array[i,:] = comparison(query_pred[i])\n",
    "print (time.clock() - start)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_array = main_array.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "filename = 'output_brute_force.csv'\n",
    "a = open(filename, 'a')\n",
    "\n",
    "headers = ['Query', 'Closest-1','Closest-2','Closest-3']\n",
    "writer = csv.DictWriter(a, delimiter='\\t', lineterminator='\\n',fieldnames=headers)\n",
    "fileEmpty = os.stat(filename).st_size == 0\n",
    "writer.writeheader()\n",
    "for i in range(len(main_array)):\n",
    "    a.write((str(query_questions.iloc[i])).split('\\n')[0].split('    ')[1]+'\\t'+str(data_questions.iloc[main_array[i][0]]).split('\\n')[0].split('    ')[1] +'\\t'+ str(data_questions.iloc[main_array[i][1]]).split('\\n')[0].split('    ')[1] +'\\t'+ str(data_questions.iloc[main_array[i][2]]).split('\\n')[0].split('    ')[1] + \"\\n\")\n",
    "a.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_brute = pd.read_csv('output_brute_force.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Closest-1</th>\n",
       "      <th>Closest-2</th>\n",
       "      <th>Closest-3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the things that we can do to bring change in Indian education system?</td>\n",
       "      <td>What are the things that we can do to bring change in Indian education system?</td>\n",
       "      <td>What are the things that we can do to bring change in Indian education system?</td>\n",
       "      <td>What are the things that we can do to bring change in Indian education system?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is Donald Trump in league with Putin?</td>\n",
       "      <td>Is Donald Trump in league with Putin?</td>\n",
       "      <td>Is Donald Trump in league with Putin?</td>\n",
       "      <td>What are some ways to contact Jesse Ventura?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What does Bootstrap do?</td>\n",
       "      <td>What is Kairos like?</td>\n",
       "      <td>What is frugal?</td>\n",
       "      <td>What's so special about Grana?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why did Sanskrit fail to become a suitable language for computers?</td>\n",
       "      <td>Why did Sanskrit fail to become a suitable language for computers?</td>\n",
       "      <td>Why did Sanskrit fail to become a suitable language for computers?</td>\n",
       "      <td>Technology: Are we compromising on wisdom over information?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can I increase my typing speed fast?</td>\n",
       "      <td>How can I increase my typing speed fast?</td>\n",
       "      <td>How can I increase my typing speed fast?</td>\n",
       "      <td>How can I increase my typing speed fast?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Query  \\\n",
       "0  What are the things that we can do to bring change in Indian education system?   \n",
       "1  Is Donald Trump in league with Putin?                                            \n",
       "2  What does Bootstrap do?                                                          \n",
       "3  Why did Sanskrit fail to become a suitable language for computers?               \n",
       "4  How can I increase my typing speed fast?                                         \n",
       "\n",
       "                                                                        Closest-1  \\\n",
       "0  What are the things that we can do to bring change in Indian education system?   \n",
       "1  Is Donald Trump in league with Putin?                                            \n",
       "2  What is Kairos like?                                                             \n",
       "3  Why did Sanskrit fail to become a suitable language for computers?               \n",
       "4  How can I increase my typing speed fast?                                         \n",
       "\n",
       "                                                                        Closest-2  \\\n",
       "0  What are the things that we can do to bring change in Indian education system?   \n",
       "1  Is Donald Trump in league with Putin?                                            \n",
       "2  What is frugal?                                                                  \n",
       "3  Why did Sanskrit fail to become a suitable language for computers?               \n",
       "4  How can I increase my typing speed fast?                                         \n",
       "\n",
       "                                                                        Closest-3  \n",
       "0  What are the things that we can do to bring change in Indian education system?  \n",
       "1  What are some ways to contact Jesse Ventura?                                    \n",
       "2  What's so special about Grana?                                                  \n",
       "3  Technology: Are we compromising on wisdom over information?                     \n",
       "4  How can I increase my typing speed fast?                                        "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_brute.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Top-3 Closest from the Training data for a given Input Query using KMeans Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the search space faster, I used KMeans clustering. Firstly, I trained Kmeans on the training data to get the cluster centers then predicted a cluster center for every new query. This improved the performance massively. Comparing to the brute-force method, Kmeans gave me top-3 results within `200secs` that too when I had not 100 but 1000 query questions against 650K questions and without any performance loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans=KMeans(n_clusters=20, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_fit = kmeans.fit(data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19,  7, 16, ..., 17, 15, 14], dtype=int32)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_fit.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 128)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_centers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_data_pred = kmeans.predict(data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(646858,)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_data_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kmeans_model.pickle', 'wb') as f:\n",
    "     pickle.dump(kmeans_fit, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    index = np.where(kmeans_data_pred == i)\n",
    "    np.array(cluster_centers[i]).dump(open('clusters/cluster_center[%s].npy' % i, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.zeros((1000,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(cluster,j):\n",
    "    #print (cluster)\n",
    "    assign = dict()\n",
    "    a = np.where(kmeans_data_pred == cluster)[0]\n",
    "    for i in a:\n",
    "        dist = np.linalg.norm(query_pred[j] - data_pred[i])\n",
    "        assign[i] = dist\n",
    "    sorted_by_value = sorted(assign.items(), key=lambda kv: kv[1])\n",
    "    a = [i for i, v in (sorted_by_value)]\n",
    "    return (a[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201.52732800000013\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.clock()\n",
    "for i in range(1000):\n",
    "    array[i,:] = compare(kmeans.predict(query_pred[i].reshape(-1,128)),i)\n",
    "print (time.clock() - start)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = array.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "filename = 'output_kmeans.csv'\n",
    "a = open(filename, 'w')\n",
    "\n",
    "headers = ['Query', 'Closest-1','Closest-2','Closest-3']\n",
    "writer = csv.DictWriter(a, delimiter='\\t', lineterminator='\\n',fieldnames=headers)\n",
    "fileEmpty = os.stat(filename).st_size == 0\n",
    "writer.writeheader()\n",
    "\n",
    "for i in range(len(array)):\n",
    "    a.write((str(query_questions.iloc[i])).split('\\n')[0].split('    ')[1] + '\\t' + str(data_questions.iloc[array[i][0]]).split('\\n')[0].split('    ')[1] + '\\t' + str(data_questions.iloc[array[i][1]]).split('\\n')[0].split('    ')[1] + '\\t' + str(data_questions.iloc[array[i][2]]).split('\\n')[0].split('    ')[1] + \"\\n\")\n",
    "a.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kmeans = pd.read_csv('output_kmeans.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Closest-1</th>\n",
       "      <th>Closest-2</th>\n",
       "      <th>Closest-3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the things that we can do to bring change in Indian education system?</td>\n",
       "      <td>What are the things that we can do to bring change in Indian education system?</td>\n",
       "      <td>What are the things that we can do to bring change in Indian education system?</td>\n",
       "      <td>What are the things that we can do to bring change in Indian education system?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is Donald Trump in league with Putin?</td>\n",
       "      <td>Is Donald Trump in league with Putin?</td>\n",
       "      <td>Is Donald Trump in league with Putin?</td>\n",
       "      <td>What are some ways to contact Jesse Ventura?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What does Bootstrap do?</td>\n",
       "      <td>What is Kairos like?</td>\n",
       "      <td>What is frugal?</td>\n",
       "      <td>What is a Discord chat?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why did Sanskrit fail to become a suitable language for computers?</td>\n",
       "      <td>Why did Sanskrit fail to become a suitable language for computers?</td>\n",
       "      <td>Why did Sanskrit fail to become a suitable language for computers?</td>\n",
       "      <td>Technology: Are we compromising on wisdom over information?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can I increase my typing speed fast?</td>\n",
       "      <td>How can I increase my typing speed fast?</td>\n",
       "      <td>How can I increase my typing speed fast?</td>\n",
       "      <td>How can I increase my typing speed fast?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Query  \\\n",
       "0  What are the things that we can do to bring change in Indian education system?   \n",
       "1  Is Donald Trump in league with Putin?                                            \n",
       "2  What does Bootstrap do?                                                          \n",
       "3  Why did Sanskrit fail to become a suitable language for computers?               \n",
       "4  How can I increase my typing speed fast?                                         \n",
       "\n",
       "                                                                        Closest-1  \\\n",
       "0  What are the things that we can do to bring change in Indian education system?   \n",
       "1  Is Donald Trump in league with Putin?                                            \n",
       "2  What is Kairos like?                                                             \n",
       "3  Why did Sanskrit fail to become a suitable language for computers?               \n",
       "4  How can I increase my typing speed fast?                                         \n",
       "\n",
       "                                                                        Closest-2  \\\n",
       "0  What are the things that we can do to bring change in Indian education system?   \n",
       "1  Is Donald Trump in league with Putin?                                            \n",
       "2  What is frugal?                                                                  \n",
       "3  Why did Sanskrit fail to become a suitable language for computers?               \n",
       "4  How can I increase my typing speed fast?                                         \n",
       "\n",
       "                                                                        Closest-3  \n",
       "0  What are the things that we can do to bring change in Indian education system?  \n",
       "1  What are some ways to contact Jesse Ventura?                                    \n",
       "2  What is a Discord chat?                                                         \n",
       "3  Technology: Are we compromising on wisdom over information?                     \n",
       "4  How can I increase my typing speed fast?                                        "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_kmeans.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
